[
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "Before beginning: adding libraries so our code runs smoothly (messages and warnings silenced).\nlibrary(\"dplyr\")\nlibrary(\"tidyverse\")\nlibrary(\"tidymodels\")\nlibrary(\"caret\")\nlibrary(\"yardstick\")\nlibrary(\"ranger\")"
  },
  {
    "objectID": "Modeling.html#basic-introduction",
    "href": "Modeling.html#basic-introduction",
    "title": "Modeling",
    "section": "Basic Introduction",
    "text": "Basic Introduction\nAgain, for this project we are using a data set about diabetes health. The data comes from the CDC, and the set we are using is clean data. We are told that we have a binary response variable called Diabetes_binary, which tells us if the person does not have diabetes or has pre-diabetes/diabetes. There are 21 variables total, but for the purpose of this project we are only choosing 3 variables in addition to the response variable to focus on. I chose to focus on physical activity (0 means no physical activity in the past 30 days, 1 means the person did engage in physical activity in the past 30 days), body mass index (continuous numeric variable),, and fruits (0 means the person does not consume fruit 1 or more times per day, 1 means the person consumes 1 or more fruits each day).\nIn the EDA .qmd file, I explained why I chose these three variables specifically already (you can go back to the EDA page here). So here, I will talk a little bit about the difference between this Modeling file and the EDA file completed previously. Exploratory data analysis has already been performed so that we have a better understanding and vision of the data set overall. Now, attention is turned to modeling so that we can look at historical data and try to predict what similar data might look like in the future. There are many different types of models that can be selected for a data set, and this project will cover and explain 4 of them specifically. The goal of this document is to choose the model that best fits the data set at hand (e.g. select the model that does the best job at predicting data in this context).\nHere, I am presenting the clean/factored data set again (from the EDA.qmd file) for use in the Modeling.qmd file:\n\n#this code is repeated from the EDA file\n\ndiabetes &lt;- read.csv(\"data/diabetes_binary_health_indicators_BRFSS2015.csv\")\n\ndiabetes$response &lt;- factor(diabetes$Diabetes_binary, levels = c(0, 1), labels = c(\"No Diabetes\", \"Has Prediabetes or Diabetes\")) #response variable is Diabetes_binary\n\ndiabetes$HighBP &lt;- factor(diabetes$HighBP, levels = c(0, 1), labels = c(\"No High BP\", \"High BP\")) \n\ndiabetes$HighChol &lt;- factor(diabetes$HighChol, levels = c(0, 1), labels = c(\"No High Chol\", \"High Chol\"))\n\ndiabetes$CholCheck &lt;- factor(diabetes$CholCheck, levels = c(0, 1), labels = c(\"Does Not Check Cholesterol\", \"Does Check Cholesterol\")) \n\ndiabetes$Smoker &lt;- factor(diabetes$Smoker, levels = c(0, 1), labels = c(\"Not Smoker\", \"Smoker\"))\n\ndiabetes$Stroke &lt;- factor(diabetes$Stroke, levels = c(0, 1), labels = c(\"No Stroke\", \"Has Had Stroke\")) \n\ndiabetes$HeartDiseaseorAttack &lt;- factor(diabetes$HeartDiseaseorAttack, levels = c(0, 1), labels = c(\"No Heart Disease\", \"Has Had Heart Disease\"))\n\ndiabetes$PhysActivity &lt;- factor(diabetes$PhysActivity, levels = c(0, 1), labels = c(\"Does Not Exercise\", \"Exercises\")) \n\ndiabetes$Fruits &lt;- factor(diabetes$Fruits, levels = c(0, 1), labels = c(\"Does Not Eat Fruit\", \"Eats Fruit\")) \n\ndiabetes$Veggies &lt;- factor(diabetes$Veggies, levels = c(0, 1), labels = c(\"Does Not Eat Veggies\", \"Eats Veggies\")) \n\ndiabetes$HvyAlcoholConsump &lt;- factor(diabetes$HvyAlcoholConsump, levels = c(0, 1), labels = c(\"Not A Heavy Drinker\", \"Heavy Drinker\")) \n\ndiabetes$AnyHealthcare &lt;- factor(diabetes$AnyHealthcare, levels = c(0, 1), labels = c(\"No Healthcare\", \"Has Healthcare\")) \n\ndiabetes$NoDocbcCost &lt;- factor(diabetes$NoDocbcCost, levels = c(0, 1), labels = c(\"No Cost Barrier In Seeing Doctor\", \"Cost Barrier In Seeing Doctor\")) \n\ndiabetes$GenHlth &lt;- factor(diabetes$GenHlth, levels = c(1:5), labels = c(\"Excellent Health\", \"Very Good Health\", \"Good Health\", \"Fair Health\", \"Poor Health\")) \n\ndiabetes$DiffWalk &lt;- factor(diabetes$DiffWalk, levels = c(0, 1), labels = c(\"No Difficulty Walking\", \"Has Difficulty Walking\")) \n\ndiabetes$Sex &lt;- factor(diabetes$Sex, levels = c(0, 1), labels = c(\"Female\", \"Male\"))\n\ndiabetes$Age &lt;- factor(diabetes$Age, levels = c(1:13), labels = c(\"18 - 24\", \"25 - 29\", \"30 - 34\", \"35 - 39\", \"40 - 44\", \"45 - 49\", \"50 - 54\", \"55 - 59\", \"60 - 64\", \"65 - 69\", \"70 - 74\", \"75 - 79\", \"80+\")) \n\ndiabetes$Education &lt;- factor(diabetes$Education, levels = c(1:6), labels = c(\"No School/K Only\", \"Elementary School\", \"Middle School\", \"High School\", \"College\", \"Graduate Education\")) \n\ndiabetes$Income &lt;- factor(diabetes$Income, levels = c(1:8), labels = c(\"Less than $10,000\", \"$10,000 - less than $15,000\", \"$15,000 - less than $20,000\", \"$20,000 - less than $25,000\", \"$25,000 - less than $35,000\", \"$35,000 - less than $50,000\", \"$50,000 - less than $75,000\", \"More than $75,000\"))\n\nTo train a model but not make it wholly dependent on data it has already seen, we will split the data we do have into training and test data. The model will be trained on the training data, and then its performance will be evaluated on the test data. We use set.seed() first to produce reproducible random numbers for the purposes of model training/testing.\n\nset.seed(100) #chose 100 because it is a similar value to our HW5 assignment \n\nsplit &lt;- initial_split(diabetes, prop = 0.7) #project instructions specify 70/30 split \ntrain &lt;- training(split)\ntest &lt;- testing(split)\n\nfolds &lt;- vfold_cv(train, 5) #project instructions specify 5 folds  \n\nAgain, the ultimate goal of this Modeling file is to create models for predicting diabetes status and then select the model that is best at predicting. Per project instructions, it’s ok to use the caret package. We are using logLoss as the metric for evaluation. All model types will use logLoss with a 5 fold cross-validation, and grids of tuning parameters are to be set up where possible."
  },
  {
    "objectID": "Modeling.html#logistic-regression-models",
    "href": "Modeling.html#logistic-regression-models",
    "title": "Modeling",
    "section": "Logistic Regression Models",
    "text": "Logistic Regression Models\nLogistic regression models are indicated for use when the response variable is binary and there is a classification task at hand. For our data, this is indeed the case. With a logistic regression model, we aim to predict the probability that the response is either 0 (does not have diabetes) or 1 (has prediabetes/diabetes). Logistic regression models employ log-odds instead of modeling the response directly (e.g. like linear regression does).\nOf note, the project instructions say “You should set up your own grid of tuning parameters in any model where that is possible.” This logistic regression model will be the only model where this is NOT possible.\n\n#creating the recipe for each of our 3 log reg models, as specified in project instructions \nlog_phys &lt;- recipe(response ~ PhysActivity + BMI, data = train) |&gt;\n  step_normalize(BMI) #normalize numeric variables; for logreg, it's unnecessary to do step_dummy()\nlog_bmi &lt;- recipe(response ~ BMI, data = train) |&gt;\n  step_normalize(BMI)\nlog_fruits &lt;- recipe(response ~ Fruits + BMI, data = train) |&gt;\n  step_normalize(BMI)\n\nspec_log &lt;- logistic_reg() |&gt;\n  set_engine(\"glm\") \n\n#setting the workflow for each model we want to test \nlogphys_wfl &lt;- workflow() |&gt;\n  add_recipe(log_phys) |&gt;\n  add_model(spec_log)\nlogbmi_wfl &lt;- workflow() |&gt;\n  add_recipe(log_bmi) |&gt;\n  add_model(spec_log)\nlogfruits_wfl &lt;- workflow() |&gt;\n  add_recipe(log_fruits) |&gt;\n  add_model(spec_log)\n\nmetrics &lt;- metric_set(mn_log_loss)\n\n#using the folds we already created to fit the models\nlogphys_fit &lt;- logphys_wfl |&gt;\n  fit_resamples(folds, metrics = metrics)\nlogbmi_fit &lt;- logbmi_wfl |&gt;\n  fit_resamples(folds, metrics = metrics)\nlogfruits_fit &lt;- logfruits_wfl |&gt;\n  fit_resamples(folds, metrics = metrics)\n\n#viewing together the metrics (log loss) for all our models in order to determine the best model\nrbind(logphys_fit |&gt; collect_metrics(),\n      logbmi_fit |&gt; collect_metrics(),\n      logfruits_fit |&gt; collect_metrics()) |&gt;\n  mutate(Model = c(\"Physical Activity + BMI Model\", \"BMI Only Model\", \"Fruit Consumption + BMI Model\")) |&gt;\n  select(Model, everything())\n\n# A tibble: 3 × 7\n  Model                         .metric   .estimator  mean     n std_err .config\n  &lt;chr&gt;                         &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n1 Physical Activity + BMI Model mn_log_l… binary     0.380     5 0.00166 Prepro…\n2 BMI Only Model                mn_log_l… binary     0.384     5 0.00174 Prepro…\n3 Fruit Consumption + BMI Model mn_log_l… binary     0.383     5 0.00179 Prepro…\n\n\nThe best model using cross-validation and log loss as the metric includes predictors of both physical activity and BMI (smallest log loss)."
  },
  {
    "objectID": "Modeling.html#classification-tree",
    "href": "Modeling.html#classification-tree",
    "title": "Modeling",
    "section": "Classification Tree",
    "text": "Classification Tree\nClassification tree models are also used when the response variable is categorical, though in this case it doesn’t necessarily have to be binary (unlike logistic regression). They are useful in classification tasks and are able to split into branches based on explanatory variables. For example, with our variable about fruit consumption status, there would be separate branches for “eats fruit - yes” and “eats fruit - no”. At the end of classification, the prediction is chosen based on which answer is the majority.\nOf note, the logistic regression model instructions above prompted us to fit three different models and choose from the three. For this classification tree task, we are only fitting ONE model that has varying values for the complexity parameter - then choosing the best model using log loss after tuning the complexity parameter. So there will not be three separate models for this section in the same way as appeared in the last section.\n\n#again, only using one model here (I chose the model that performed the best in the logreg section) but altering the complexity parameter later on\ntree &lt;- recipe(response ~ PhysActivity + BMI, data = train) |&gt;\n  step_dummy(PhysActivity) |&gt; #do need step_dummy() for this categorical variable\n  step_normalize(BMI)\n\ntree_spec &lt;- decision_tree(tree_depth = 5, \n                              min_n = 10, \n                              cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\ntree_wfl &lt;- workflow() |&gt;\n  add_recipe(tree) |&gt;\n  add_model(tree_spec)\n\nmetrics &lt;- metric_set(mn_log_loss)\n\n#this is how I'm putting different values for cost complexity per the project instructions\ngrid &lt;- tibble(cost_complexity = 10^seq(-4, -1, length.out = 10))\n\ntune &lt;- tune_grid(\n  tree_wfl,\n  resamples = folds, \n  grid = grid,\n  metrics = metrics\n)\n\n#this should select the best model based on cost complexity/log loss  \nbest_tree &lt;- select_best(tune, metric = \"mn_log_loss\")\n\ntree_final_wfl &lt;- tree_wfl |&gt;\n  finalize_workflow(best_tree)\n\ntree_final_fit &lt;- tree_final_wfl |&gt;\n  last_fit(split, metrics = metrics)\n\n#we only have one model for this section, and we're able to see the resulting log less metric \ntree_final_fit |&gt; collect_metrics()\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 mn_log_loss binary         0.404 Preprocessor1_Model1\n\n\nThe best model using cross-validation and log loss has a complexity parameter of 0.0001. The log loss is 0.404."
  },
  {
    "objectID": "Modeling.html#random-forest",
    "href": "Modeling.html#random-forest",
    "title": "Modeling",
    "section": "Random Forest",
    "text": "Random Forest\nRandom forest models take the idea of classification trees one step farther by relying on multiple trees as well as bootstrapped samples to make a prediction. The average result will serve as a final prediction: majority for categorical or mean for numerical. One key to random forest models is that splits occur based on a random subset of predictors each time - the number of predictors is the tuning parameter. In other words, random forests do not use every single predictor at each step. Bootstrapping is key here in order to reduce overfitting and improve the ability for the model to generalize in the context of random forest models. Bootstrapping means that the training data being used for the model will be sampled with replacement in order to get more mileage out of the training data we have. This means that every tree in the forest will be trained with a slightly different version of the training data. The overall ideal is that if there is a very strong predictor, each bootstrapped tree will likely use it for the first split.\n\n#again here, making recipes with step_dummy() and step_normalize\nrtree_phys &lt;- recipe(response ~ PhysActivity + BMI, data = train) |&gt;\n  step_dummy(PhysActivity) |&gt;\n  step_normalize(BMI)\nrtree_bmi &lt;- recipe(response ~ BMI, data = train) |&gt;\n  step_normalize(BMI) \nrtree_fruits &lt;- recipe(response ~ Fruits + BMI, data = train) |&gt;\n  step_dummy(Fruits) |&gt;\n  step_normalize(BMI)\n\nrtree_spec &lt;- rand_forest(mtry = tune()) |&gt;\n  set_engine(\"ranger\") |&gt;\n  set_mode(\"classification\")\n\n#making workflows for the differnet models \nrtreephys_wfl &lt;- workflow() |&gt;\n  add_recipe(rtree_phys) |&gt;\n  add_model(rtree_spec)\nrtreebmi_wfl &lt;- workflow() |&gt;\n  add_recipe(rtree_bmi) |&gt;\n  add_model(rtree_spec)\nrtreefruits_wfl &lt;- workflow() |&gt;\n  add_recipe(rtree_fruits) |&gt;\n  add_model(rtree_spec)\n\nmetrics &lt;- metric_set(mn_log_loss)\n\n#using folds for runing for the models \nrtreephys_fit &lt;- rtreephys_wfl |&gt;\n  tune_grid(resamples = folds, metrics = metrics)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\nrtreebmi_fit &lt;- rtreebmi_wfl |&gt;\n  tune_grid(resamples = folds, metrics = metrics)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\nrtreefruits_fit &lt;- rtreefruits_wfl |&gt;\n  tune_grid(resamples = folds, metrics = metrics)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n#choosing the best of each model \nbest_rphys &lt;- select_best(rtreephys_fit, metric = \"mn_log_loss\")\nbest_rbmi &lt;- select_best(rtreebmi_fit, metric = \"mn_log_loss\")\nbest_rfruits &lt;- select_best(rtreefruits_fit, metric = \"mn_log_loss\")\n\nrphys_final_wfl &lt;- rtreephys_wfl |&gt;\n  finalize_workflow(best_rphys)\nrbmi_final_wfl &lt;- rtreebmi_wfl |&gt;\n  finalize_workflow(best_rbmi)\nrfruits_final_wfl &lt;- rtreefruits_wfl |&gt;\n  finalize_workflow(best_rfruits)\n\nrphys_final_fit &lt;- rphys_final_wfl |&gt;\n  last_fit(split, metrics = metrics)\nrbmi_final_fit &lt;- rbmi_final_wfl |&gt;\n  last_fit(split, metrics = metrics)\nrfruits_final_fit &lt;- rfruits_final_wfl |&gt;\n  last_fit(split, metrics = metrics)\n\n#putting the best model fits together to compare them side by side based on log loss metric\nbind_rows(rphys_final_fit |&gt; collect_metrics() |&gt; mutate(Model = \"Physical Activity + BMI Model\"),\n      rbmi_final_fit |&gt; collect_metrics() |&gt; mutate(Model = \"BMI Only Model\"),\n      rfruits_final_fit |&gt; collect_metrics() |&gt; mutate(Model = \"Fruit Consumption + BMI Model\")) |&gt;\n  filter(.metric == \"mn_log_loss\") |&gt;\n  select(Model, Log_Loss = .estimate)\n\n# A tibble: 3 × 2\n  Model                         Log_Loss\n  &lt;chr&gt;                            &lt;dbl&gt;\n1 Physical Activity + BMI Model    0.377\n2 BMI Only Model                   0.378\n3 Fruit Consumption + BMI Model    0.379\n\n\nThe best model using cross-validation and log loss as the metric includes predictors of both physical activity and BMI (smallest log loss)."
  },
  {
    "objectID": "Modeling.html#final-model-selection",
    "href": "Modeling.html#final-model-selection",
    "title": "Modeling",
    "section": "Final Model Selection",
    "text": "Final Model Selection\nNow that we have identified the best model from the three model types above, we will compare the models to each other based on the log loss metric to pick the best model out of the three types.\n\n#the logreg model is the only one that hasn't undergone a last fit yet, so doing that now \nlogbmi_final_fit &lt;- logphys_wfl |&gt;\n  last_fit(split, metrics = metric_set(mn_log_loss))\n\n#putting all three models together to view side by side \nbind_rows(logbmi_final_fit |&gt; collect_metrics() |&gt; mutate(Model = \"Logistic Regression Model\"),\n      tree_final_fit |&gt; collect_metrics() |&gt; mutate(Model = \"Classification Tree Model\"),\n      rphys_final_fit |&gt; collect_metrics() |&gt; mutate(Model = \"Random Forest Model\")) |&gt;\n  filter(.metric == \"mn_log_loss\") |&gt;\n  select(Model, Log_Loss = .estimate)\n\n# A tibble: 3 × 2\n  Model                     Log_Loss\n  &lt;chr&gt;                        &lt;dbl&gt;\n1 Logistic Regression Model    0.381\n2 Classification Tree Model    0.404\n3 Random Forest Model          0.377\n\n\nThe best model using cross-validation and log loss as the metric is the Random Forest Physical Activity + BMI model (smallest log loss)."
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "EDA",
    "section": "",
    "text": "Before beginning: adding libraries so our code runs smoothly (messages and warnings silenced).\nlibrary(\"dplyr\")\nlibrary(\"ggplot2\")"
  },
  {
    "objectID": "EDA.html#introduction-section",
    "href": "EDA.html#introduction-section",
    "title": "EDA",
    "section": "Introduction Section",
    "text": "Introduction Section\nBriefly describe the data and the variables you have to work with.\nFor this project, we are using a specific set of the Diabetes Health Indicators data. The data we are working with is clean data that contains survey responses from the CDC. We are told that the response variable is Diabetes_binary, where 0 means the person does not have diabetes, and 1 means the person has pre-diabetes or diabetes (specifically for this particular data set, we are working with the variable Diabetes_binary which only includes these two classes, rather than having 3 groups for no diabetes, pre-diabetes, and diabetes). The data includes 21 variables total. The project instructions tells us to pick 3 variables (aside from the response) to explore further. I chose to focus on physical activity (0 means no physical activity in the past 30 days, 1 means the person did engage in physical activity in the past 30 days), body mass index (BMI; continuous numeric variable),, and fruits (0 means the person does not consume fruit 1 or more times per day, 1 means the person consumes 1 or more fruits each day).\nNow, I will explain a bit about why I chose these three variables to focus on. For the past 3 years, I have worked in a lab at UNC Chapel Hill studying intellectual and developmental disabilities (IDD) in younger and older adults, including autism, dementia, etc. One of the research projects studies the effects of a physical activity program (intervention) for adults with IDD. In our project narrative, we point to past research that suggests that physical activity (moderate to vigorous) can potentially delay the onset of conditions like diabetes and dementia, which are especially prevalent in IDD communities compared to the general population. Some of the measures we include in our study are body mass index and body fat percentage. We place our participants in a machine called the BodPod to investigate body composition, and do this at several time points during the participants’ time in the physical activity intervention (and/or while they are in the waitlist group for the intervention). We also ask the participants (and their caregivers) questions about their lifestyle in general: e.g., what is the participant’s baseline physical activity outside of the intervention? Do they choose to eat fruits and vegetables on their own? How often do they do this? What kind of adaptive behaviors help them complete activities of daily living? So, in summary, though this data set is not IDD-specific, I chose variables I recognized and am familiar with in thinking about factors at play for diseases like diabetes (and dementias). Because of this research I have been a part of for IDD populations, I know that it is possible there may be similar trends for a general population. Physical activity, BMI, and fruit consumption may serve as predictors for the presence of diabetes.\nDescribe the purpose of your EDA and ultimate goal of modeling.\nThe purposes of exploratory data analysis (EDA) is to better understand and get to know the data set at hand before applying deeper statistical methods (e.g. for the purposes of inference and prediction). EDA can include data cleaning - the current data set is described as clean already on its website, but I still check for missing values (for example) below. If there were missing values, I would drop them from analysis as part of EDA. EDA can also include descriptions and visualizations of the data. The present project prompts us to do both univariate and bivariate data exploration to investigate characteristics of certain variables but also give insight on how variables might relate to each other. Below, the data is visualized with plots as well, which is another part of EDA. Ultimately, EDA is a tool used to understand the structure of data, whether there are certain patterns present, whether or not certain variables have relationships with each other, and if there are any strange factors in the data that could skew analysis/modeling later on.\nModeling (which is detailed in a separate .qmd file in this project) is a mathematical representation of patterns/phenomena present in a data set (per Dr. Post!). In this class and for this project, we work a lot with predictive modeling - that is, trying to create an algorithm that can learn from a data set and then predict what that data in that specific context might look like for future observations. The ultimate goal of modeling is to be able to predict future outcomes based on historical observations. This is very important in many businesses, for example when trying to anticipate market trends to maximize profits. A large part of predictive modeling is getting to know your data through EDA so that you can decide the most appropriate type of model to pick for your data set in the first place. In other words, trying to pick the model that will be most accurate in its predictions in terms of the trends and patterns in the data set.\nNote: I tried to be as clear as possible but my narration is a mix of text and in-code comments below."
  },
  {
    "objectID": "EDA.html#data",
    "href": "EDA.html#data",
    "title": "EDA",
    "section": "Data",
    "text": "Data\nHere, I am using a relative path to import the indicated diabetes health data set.\n\ndiabetes &lt;- read.csv(\"data/diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nNow, per project instructions, I am converting “a lot of the variables [in the data set] to factors with meaningful level names.” I am making sure to use factor() only on the categorical variables that had labeled levels, and not the continuous numerical variables for which level-naming would not make sense.\n\ndiabetes$response &lt;- factor(diabetes$Diabetes_binary, levels = c(0, 1), labels = c(\"No Diabetes\", \"Has Prediabetes or Diabetes\")) #response variable is Diabetes_binary\n\ndiabetes$HighBP &lt;- factor(diabetes$HighBP, levels = c(0, 1), labels = c(\"No High BP\", \"High BP\")) \n\ndiabetes$HighChol &lt;- factor(diabetes$HighChol, levels = c(0, 1), labels = c(\"No High Chol\", \"High Chol\"))\n\ndiabetes$CholCheck &lt;- factor(diabetes$CholCheck, levels = c(0, 1), labels = c(\"Does Not Check Cholesterol\", \"Does Check Cholesterol\")) \n\ndiabetes$Smoker &lt;- factor(diabetes$Smoker, levels = c(0, 1), labels = c(\"Not Smoker\", \"Smoker\"))\n\ndiabetes$Stroke &lt;- factor(diabetes$Stroke, levels = c(0, 1), labels = c(\"No Stroke\", \"Has Had Stroke\")) \n\ndiabetes$HeartDiseaseorAttack &lt;- factor(diabetes$HeartDiseaseorAttack, levels = c(0, 1), labels = c(\"No Heart Disease\", \"Has Had Heart Disease\"))\n\ndiabetes$PhysActivity &lt;- factor(diabetes$PhysActivity, levels = c(0, 1), labels = c(\"Does Not Exercise\", \"Exercises\")) \n\ndiabetes$Fruits &lt;- factor(diabetes$Fruits, levels = c(0, 1), labels = c(\"Does Not Eat Fruit\", \"Eats Fruit\")) \n\ndiabetes$Veggies &lt;- factor(diabetes$Veggies, levels = c(0, 1), labels = c(\"Does Not Eat Veggies\", \"Eats Veggies\")) \n\ndiabetes$HvyAlcoholConsump &lt;- factor(diabetes$HvyAlcoholConsump, levels = c(0, 1), labels = c(\"Not A Heavy Drinker\", \"Heavy Drinker\")) \n\ndiabetes$AnyHealthcare &lt;- factor(diabetes$AnyHealthcare, levels = c(0, 1), labels = c(\"No Healthcare\", \"Has Healthcare\")) \n\ndiabetes$NoDocbcCost &lt;- factor(diabetes$NoDocbcCost, levels = c(0, 1), labels = c(\"No Cost Barrier In Seeing Doctor\", \"Cost Barrier In Seeing Doctor\")) \n\ndiabetes$GenHlth &lt;- factor(diabetes$GenHlth, levels = c(1:5), labels = c(\"Excellent Health\", \"Very Good Health\", \"Good Health\", \"Fair Health\", \"Poor Health\")) \n\ndiabetes$DiffWalk &lt;- factor(diabetes$DiffWalk, levels = c(0, 1), labels = c(\"No Difficulty Walking\", \"Has Difficulty Walking\")) \n\ndiabetes$Sex &lt;- factor(diabetes$Sex, levels = c(0, 1), labels = c(\"Female\", \"Male\"))\n\ndiabetes$Age &lt;- factor(diabetes$Age, levels = c(1:13), labels = c(\"18 - 24\", \"25 - 29\", \"30 - 34\", \"35 - 39\", \"40 - 44\", \"45 - 49\", \"50 - 54\", \"55 - 59\", \"60 - 64\", \"65 - 69\", \"70 - 74\", \"75 - 79\", \"80+\")) \n\ndiabetes$Education &lt;- factor(diabetes$Education, levels = c(1:6), labels = c(\"No School/K Only\", \"Elementary School\", \"Middle School\", \"High School\", \"College\", \"Graduate Education\")) \n\ndiabetes$Income &lt;- factor(diabetes$Income, levels = c(1:8), labels = c(\"Less than $10,000\", \"$10,000 - less than $15,000\", \"$15,000 - less than $20,000\", \"$20,000 - less than $25,000\", \"$25,000 - less than $35,000\", \"$35,000 - less than $50,000\", \"$50,000 - less than $75,000\", \"More than $75,000\"))\n  \nprint(head(diabetes, n = 5)) #this shows some of the labeling done\n\n  Diabetes_binary     HighBP     HighChol                  CholCheck BMI\n1               0    High BP    High Chol     Does Check Cholesterol  40\n2               0 No High BP No High Chol Does Not Check Cholesterol  25\n3               0    High BP    High Chol     Does Check Cholesterol  28\n4               0    High BP No High Chol     Does Check Cholesterol  27\n5               0    High BP    High Chol     Does Check Cholesterol  24\n      Smoker    Stroke HeartDiseaseorAttack      PhysActivity\n1     Smoker No Stroke     No Heart Disease Does Not Exercise\n2     Smoker No Stroke     No Heart Disease         Exercises\n3 Not Smoker No Stroke     No Heart Disease Does Not Exercise\n4 Not Smoker No Stroke     No Heart Disease         Exercises\n5 Not Smoker No Stroke     No Heart Disease         Exercises\n              Fruits              Veggies   HvyAlcoholConsump  AnyHealthcare\n1 Does Not Eat Fruit         Eats Veggies Not A Heavy Drinker Has Healthcare\n2 Does Not Eat Fruit Does Not Eat Veggies Not A Heavy Drinker  No Healthcare\n3         Eats Fruit Does Not Eat Veggies Not A Heavy Drinker Has Healthcare\n4         Eats Fruit         Eats Veggies Not A Heavy Drinker Has Healthcare\n5         Eats Fruit         Eats Veggies Not A Heavy Drinker Has Healthcare\n                       NoDocbcCost          GenHlth MentHlth PhysHlth\n1 No Cost Barrier In Seeing Doctor      Poor Health       18       15\n2    Cost Barrier In Seeing Doctor      Good Health        0        0\n3    Cost Barrier In Seeing Doctor      Poor Health       30       30\n4 No Cost Barrier In Seeing Doctor Very Good Health        0        0\n5 No Cost Barrier In Seeing Doctor Very Good Health        3        0\n                DiffWalk    Sex     Age          Education\n1 Has Difficulty Walking Female 60 - 64        High School\n2  No Difficulty Walking Female 50 - 54 Graduate Education\n3 Has Difficulty Walking Female 60 - 64        High School\n4  No Difficulty Walking Female 70 - 74      Middle School\n5  No Difficulty Walking Female 70 - 74            College\n                       Income    response\n1 $15,000 - less than $20,000 No Diabetes\n2           Less than $10,000 No Diabetes\n3           More than $75,000 No Diabetes\n4 $35,000 - less than $50,000 No Diabetes\n5 $20,000 - less than $25,000 No Diabetes\n\n\nNext, the instructions say to “check on missingness, etc.”. We already know from the website that the data set is clean so it makes sense that there is no missing data here. There is no need to remove any missing rows.\n\n#check missingness- no drop_na() needed\ncolSums(is.na(diabetes))\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income             response \n                   0                    0 \n\n\nNow to address the “etc.” part of the instructions above. These are some other EDA procedures we have discussed in class. ‘describe’ shows various descriptive statistics for each variable in the data set, and ‘summary’ is similar but a little less overwhelming - basically, the two functions have different focuses in describing and summarizing data.\n\npsych::describe(diabetes)\n\n                      vars      n  mean   sd median trimmed  mad min max range\nDiabetes_binary          1 253680  0.14 0.35      0    0.05 0.00   0   1     1\nHighBP*                  2 253680  1.43 0.49      1    1.41 0.00   1   2     1\nHighChol*                3 253680  1.42 0.49      1    1.41 0.00   1   2     1\nCholCheck*               4 253680  1.96 0.19      2    2.00 0.00   1   2     1\nBMI                      5 253680 28.38 6.61     27   27.68 4.45  12  98    86\nSmoker*                  6 253680  1.44 0.50      1    1.43 0.00   1   2     1\nStroke*                  7 253680  1.04 0.20      1    1.00 0.00   1   2     1\nHeartDiseaseorAttack*    8 253680  1.09 0.29      1    1.00 0.00   1   2     1\nPhysActivity*            9 253680  1.76 0.43      2    1.82 0.00   1   2     1\nFruits*                 10 253680  1.63 0.48      2    1.67 0.00   1   2     1\nVeggies*                11 253680  1.81 0.39      2    1.89 0.00   1   2     1\nHvyAlcoholConsump*      12 253680  1.06 0.23      1    1.00 0.00   1   2     1\nAnyHealthcare*          13 253680  1.95 0.22      2    2.00 0.00   1   2     1\nNoDocbcCost*            14 253680  1.08 0.28      1    1.00 0.00   1   2     1\nGenHlth*                15 253680  2.51 1.07      2    2.45 1.48   1   5     4\nMentHlth                16 253680  3.18 7.41      0    1.04 0.00   0  30    30\nPhysHlth                17 253680  4.24 8.72      0    1.77 0.00   0  30    30\nDiffWalk*               18 253680  1.17 0.37      1    1.09 0.00   1   2     1\nSex*                    19 253680  1.44 0.50      1    1.43 0.00   1   2     1\nAge*                    20 253680  8.03 3.05      8    8.17 2.97   1  13    12\nEducation*              21 253680  5.05 0.99      5    5.15 1.48   1   6     5\nIncome*                 22 253680  6.05 2.07      7    6.35 1.48   1   8     7\nresponse*               23 253680  1.14 0.35      1    1.05 0.00   1   2     1\n                       skew kurtosis   se\nDiabetes_binary        2.08     2.34 0.00\nHighBP*                0.29    -1.92 0.00\nHighChol*              0.31    -1.91 0.00\nCholCheck*            -4.88    21.83 0.00\nBMI                    2.12    11.00 0.01\nSmoker*                0.23    -1.95 0.00\nStroke*                4.66    19.69 0.00\nHeartDiseaseorAttack*  2.78     5.72 0.00\nPhysActivity*         -1.20    -0.57 0.00\nFruits*               -0.56    -1.69 0.00\nVeggies*              -1.59     0.54 0.00\nHvyAlcoholConsump*     3.85    12.85 0.00\nAnyHealthcare*        -4.18    15.48 0.00\nNoDocbcCost*           3.00     6.97 0.00\nGenHlth*               0.42    -0.38 0.00\nMentHlth               2.72     6.44 0.01\nPhysHlth               2.21     3.50 0.02\nDiffWalk*              1.77     1.15 0.00\nSex*                   0.24    -1.94 0.00\nAge*                  -0.36    -0.58 0.01\nEducation*            -0.78     0.04 0.00\nIncome*               -0.89    -0.28 0.00\nresponse*              2.08     2.34 0.00\n\nsummary(diabetes)\n\n Diabetes_binary         HighBP               HighChol     \n Min.   :0.0000   No High BP:144851   No High Chol:146089  \n 1st Qu.:0.0000   High BP   :108829   High Chol   :107591  \n Median :0.0000                                            \n Mean   :0.1393                                            \n 3rd Qu.:0.0000                                            \n Max.   :1.0000                                            \n                                                           \n                      CholCheck           BMI               Smoker      \n Does Not Check Cholesterol:  9470   Min.   :12.00   Not Smoker:141257  \n Does Check Cholesterol    :244210   1st Qu.:24.00   Smoker    :112423  \n                                     Median :27.00                      \n                                     Mean   :28.38                      \n                                     3rd Qu.:31.00                      \n                                     Max.   :98.00                      \n                                                                        \n            Stroke                  HeartDiseaseorAttack\n No Stroke     :243388   No Heart Disease     :229787   \n Has Had Stroke: 10292   Has Had Heart Disease: 23893   \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n            PhysActivity                   Fruits      \n Does Not Exercise: 61760   Does Not Eat Fruit: 92782  \n Exercises        :191920   Eats Fruit        :160898  \n                                                       \n                                                       \n                                                       \n                                                       \n                                                       \n                 Veggies                 HvyAlcoholConsump \n Does Not Eat Veggies: 47839   Not A Heavy Drinker:239424  \n Eats Veggies        :205841   Heavy Drinker      : 14256  \n                                                           \n                                                           \n                                                           \n                                                           \n                                                           \n        AnyHealthcare                              NoDocbcCost    \n No Healthcare : 12417   No Cost Barrier In Seeing Doctor:232326  \n Has Healthcare:241263   Cost Barrier In Seeing Doctor   : 21354  \n                                                                  \n                                                                  \n                                                                  \n                                                                  \n                                                                  \n             GenHlth         MentHlth         PhysHlth     \n Excellent Health:45299   Min.   : 0.000   Min.   : 0.000  \n Very Good Health:89084   1st Qu.: 0.000   1st Qu.: 0.000  \n Good Health     :75646   Median : 0.000   Median : 0.000  \n Fair Health     :31570   Mean   : 3.185   Mean   : 4.242  \n Poor Health     :12081   3rd Qu.: 2.000   3rd Qu.: 3.000  \n                          Max.   :30.000   Max.   :30.000  \n                                                           \n                   DiffWalk          Sex              Age       \n No Difficulty Walking :211005   Female:141974   60 - 64:33244  \n Has Difficulty Walking: 42675   Male  :111706   65 - 69:32194  \n                                                 55 - 59:30832  \n                                                 50 - 54:26314  \n                                                 70 - 74:23533  \n                                                 45 - 49:19819  \n                                                 (Other):87744  \n              Education                              Income     \n No School/K Only  :   174   More than $75,000          :90385  \n Elementary School :  4043   $50,000 - less than $75,000:43219  \n Middle School     :  9478   $35,000 - less than $50,000:36470  \n High School       : 62750   $25,000 - less than $35,000:25883  \n College           : 69910   $20,000 - less than $25,000:20135  \n Graduate Education:107325   $15,000 - less than $20,000:15994  \n                             (Other)                    :21594  \n                        response     \n No Diabetes                :218334  \n Has Prediabetes or Diabetes: 35346"
  },
  {
    "objectID": "EDA.html#summarizations",
    "href": "EDA.html#summarizations",
    "title": "EDA",
    "section": "Summarizations",
    "text": "Summarizations\nPer the project instructions, this is the goal of the Summarizations section: Produce meaningful summary statistic and plots about the data you are working with (especially as it relates to your response.) Do EDA on full data even though we haven’t split into training/test data first. Be sure to have a narrative about what you are exploring and what the summaries and graphs you created say about the relationships in your data.\nThe instructions also tell us to do at least one univariate exploration on the 4 variables. Below, I produce contingency tables for the categorical variables (including the response) and use ‘describe’ again but only on the single continuous numerical variable I chose. The contingency tables tell us a raw count of how many responses belong in each level of each categorical variable to give us a sense of how many responses fall in each category and how the categories compare to each other. Using ‘describe’ again for the continuous numerical variable allows us to narrow in on the variable of interest and gives us summary statistics just for that variable.\nComments/interpretations of the results are commented within the code below.\n\n#contingency tables for categorical variables\ndiabetes |&gt;\n  group_by(response) |&gt;\n  summarize(count = n()) #more without pre-diabetes/diabetes than with\n\n# A tibble: 2 × 2\n  response                     count\n  &lt;fct&gt;                        &lt;int&gt;\n1 No Diabetes                 218334\n2 Has Prediabetes or Diabetes  35346\n\ndiabetes |&gt;\n  group_by(PhysActivity) |&gt;\n  summarize(count = n()) #more that exercise than do not \n\n# A tibble: 2 × 2\n  PhysActivity       count\n  &lt;fct&gt;              &lt;int&gt;\n1 Does Not Exercise  61760\n2 Exercises         191920\n\ndiabetes |&gt;\n  group_by(Fruits) |&gt;\n  summarize(count = n()) #more that eat fruit than do not\n\n# A tibble: 2 × 2\n  Fruits              count\n  &lt;fct&gt;               &lt;int&gt;\n1 Does Not Eat Fruit  92782\n2 Eats Fruit         160898\n\n#numerical summary for the continuous variable\npsych::describe(diabetes$BMI) #average BMI of about 28, which is overweight \n\n   vars      n  mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 253680 28.38 6.61     27   27.68 4.45  12  98    86 2.12       11 0.01\n\n\nThis is also an opportunity to visualize these variables individually. I used simple bar charts for the categorical variables that give a visual aid to the contingency tables produced earlier. For the continuous numerical variable, a histogram was more appropriate. The histogram shows the distribution of the responses within the variable of BMI.\n\n#visualizing the data \nplot(diabetes$response, xlab = \"Diabetes Status\", ylab = \"# of Responses\", main = \"Bar Chart of Diabetes Status\")\n\n\n\nplot(diabetes$PhysActivity, xlab = \"Physical Activity Status\", ylab = \"# of Responses\", main = \"Bar Chart of Physical Activity Status\")\n\n\n\nplot(diabetes$Fruits, xlab = \"Fruit Consumption Status\", ylab = \"# of Responses\", main = \"Bar Chart of Fruit Consumption Status\")\n\n\n\nhist(diabetes$BMI, xlab = \"BMI\", main = \"Histogram of Body Mass Index (BMI) Responses\") #distribution shows a right skew (mean is greater than median)\n\n\n\n\nThen, the project instructions tell us to include exploration of the bivariate relationships between explanatory variables and the response. For the categorical variables, I made faceted bar charts to show both the explanatory and response variables in the same graph. The coloring inside the bars show the outcomes of the response variable, while the explanatory variable is on the x axis and the proportion on the y (e.g. the relative frequency of the response in each explanatory category). The table() function after each graph is a numerical way to show this same relationship (rather than mostly visual). Finally, I performed Chi Square tests to see if there was significance in the relationships between the explanatory and the response (e.g., if significant it is less likely that observed differences in x1 across x2 are due to chance alone).\nFor the continuous numerical variable, I strove for similar outcomes, but due to the nature of the data used a boxplot and ANOVA instead.\nComments/interpretations of the results are commented within the code below.\n\n#look at bivariate relationships between each of your explanatory variables and the response\n\n#physical activity and diabetes status\nggplot(diabetes, aes(x = PhysActivity, fill = response)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Physical Activity Status\", y = \"Proportion\", fill = \"Diabetes Status\", \n       main = \"Physical Activity as a Predictor of Diabetes Status\") #the \"does not exercise\" group had more participants with pre-diabetes/diabetes than the \"exercises\" group. \n\n\n\ntable(diabetes$PhysActivity, diabetes$response) #numerical representation of the graph above, though not in proportions so must account for that when looking at the numbers.\n\n                   \n                    No Diabetes Has Prediabetes or Diabetes\n  Does Not Exercise       48701                       13059\n  Exercises              169633                       22287\n\nchisq.test(diabetes$PhysActivity, diabetes$response) #a small p-value here means that the observed differences difference in diabetes status across physical activity status groups is likely not due to chance. In other words, there may be a statistically significant association between physical activity level and diabetes status.  \n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  diabetes$PhysActivity and diabetes$response\nX-squared = 3539.4, df = 1, p-value &lt; 2.2e-16\n\n#fruit consumption and diabetes status\nggplot(diabetes, aes(x = Fruits, fill = response)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Fruit Consumption Status\", y = \"Proportion\", fill = \"Diabetes Status\",\n       main = \"Fruit Consumption as a Predictor of Diabetes Status\") #the \"does not eat fruit\" group had more participants with pre-diabetes/diabetes than the \"eats fruit\" group. \n\n\n\ntable(diabetes$Fruits, diabetes$response) #numerical representation of the graph above, though not in proportions so must account for that when looking at the numbers.\n\n                    \n                     No Diabetes Has Prediabetes or Diabetes\n  Does Not Eat Fruit       78129                       14653\n  Eats Fruit              140205                       20693\n\nchisq.test(diabetes$Fruits, diabetes$response) #a small p-value here means that the observed differences difference in diabetes status across fruit consumption groups is likely not due to chance. In other words, there may be a statistically significant association between physical activity level and fruit consumption.   \n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  diabetes$Fruits and diabetes$response\nX-squared = 421.61, df = 1, p-value &lt; 2.2e-16\n\n#BMI and diabetes status \nboxplot(BMI ~ response, data = diabetes, ylab = \"Diabetes Status\", main = \"BMI Value by Diabetes Status\") #the \"has pre-diabetes or diabetes\" group had a higher average BMI than the \"no diabetes\" group. \n\n\n\nanova &lt;- aov(BMI ~ response, data = diabetes)\nsummary(anova) #a small p-value here means that the observed differences in BMI across diabetes status groups is likely not due to chance. In other words, there may be a statistically significant association between BMI and diabetes status.  \n\n                Df   Sum Sq Mean Sq F value Pr(&gt;F)    \nresponse         1   520963  520963   12517 &lt;2e-16 ***\nResiduals   253678 10558426      42                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn EDA summary, the explanatory variables I chose seem to be promising predictors of diabetes status. Modeling will help us understand and leverage these relationships further.\n(At the bottom of the EDA file, give a link to the modeling page: Click here for the Modeling Page)"
  }
]